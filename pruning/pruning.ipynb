{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdb6469-26b1-404b-be15-89fe646debdc",
   "metadata": {},
   "source": [
    "# Pruning \n",
    "Pruning can signficantly decrease the model size, make inference faster and easier to deploy, especially when combined with quantization and knowledge distillation. Pruning can remove unnecessary neurons, channels, layers, and entire filters. There are two types of pruning: \n",
    "\n",
    "    - Unstructured: Prune individual weights (sparse)\n",
    "    - Structured : Remove entire filters/channels/layers (can be more hardware-friendly)\n",
    "\n",
    "We're gonna try to prune resnet here. And because it has \"res\"idual connections, we need to be careful how we do it. Usually, we don't prune batch norm layer, those are important for stability. We can apply structured pruning to conv layers, and unstructured pruning to linear layers. Typically, when we do pruning, the accuracy can drop, so we may need to fine-tune the prune the model. Quantization can then follow to make the models even smaller. \n",
    "\n",
    "One thing to note about sparse models is that they're not necessarily faster. You need \"sparse kernels\" or post-training to utilize that sparsity. Unstructured pruning just set the weight to zero, it doesn't remove them. You need a backend that understand how to remove them. \n",
    "\n",
    "Sparse kernel is special operator that detect sparse weights, skips computations on zero weights, and uses compressed sparse row formats. Torch and ONNX have compilers that can help with that. \n",
    "\n",
    "We'll use pytorch to help us do the pruning in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e3f4d7-4d18-4a8c-83e5-d5ae06671c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "import time \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008e3476-f2c0-4c04-b66e-9355cc5f4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transforms for ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2. Load STL10 test set (we'll use test set for evaluation)\n",
    "train_ds = datasets.STL10(root=\"../data\", split=\"train\", download=True, transform=transform)\n",
    "test_ds  = datasets.STL10(root=\"../data\", split=\"test\",  download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "num_labels = 10\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afe89bd6-0d04-4da8-8cc3-0214c976b1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load teacher model\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.load_state_dict(torch.load(\"../data/teacher_resnet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23807de7-b846-4a93-a4d1-e837fd16d471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on STL10 test set: 92.58%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x).argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"Accuracy on STL10 test set: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023434f8-c430-4d44-8aa9-31ce8c3cde71",
   "metadata": {},
   "source": [
    "# Time for pruning \n",
    "\n",
    "Torch doesn't actually zero the weight, it creates a mask that gets applied to the weights during the forward pass. We could also just remove the weights during pruning using: \n",
    "\n",
    "    prune.remove(module, \"weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d51f972-b2f6-47a4-9fc7-fc00aea91da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pruned_weights(model):\n",
    "    total, zero = 0, 0\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, \"weight_mask\") and hasattr(module, \"weight_orig\"):\n",
    "            mask = module.weight_mask\n",
    "            numel = mask.numel()\n",
    "            total += numel\n",
    "            zero += (mask == 0).sum().item()\n",
    "    return total, zero\n",
    "\n",
    "\n",
    "def apply_unstructured_pruning(model, amount=0.5):\n",
    "    \"\"\"\n",
    "    Apply unstructured L1-norm pruning to Conv2d and Linear layers.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd62c1ac-3dea-4af5-9865-798a5f3f827b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load teacher model\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.load_state_dict(torch.load(\"../data/teacher_resnet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24d3d4a4-3fec-4aef-a7c1-15ebf963fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 11,172,032\n",
      "Zeroed (pruned) params: 5,586,016 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "model_pruned = apply_unstructured_pruning(model, amount=0.5)\n",
    "total, zero = count_pruned_weights(model_pruned)\n",
    "print(f\"Total params: {total:,}\")\n",
    "print(f\"Zeroed (pruned) params: {zero:,} ({100 * zero/total:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8926a6-c010-4267-9077-52b0a81c5956",
   "metadata": {},
   "source": [
    "You can see that now there are these \"weight_mask\" in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61d19b6b-bb86-42d3-b869-14b1e40b6953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(hasattr(model_pruned.layer1[0].conv1, \"weight_orig\"))   # True\n",
    "print(hasattr(model_pruned.layer1[0].conv1, \"weight_mask\"))   # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8faeb6eb-8d6a-4eee-be1c-0b077f1d99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on STL10 test set: 66.25%\n"
     ]
    }
   ],
   "source": [
    "model_pruned.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model_pruned(x).argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"Accuracy on STL10 test set: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c436b-c218-496b-ba27-8afd593c37b4",
   "metadata": {},
   "source": [
    "Not surprisingly the perforamnce dropped. Let's fine-tune it and see if that can help recover some of the performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c07ded-cac2-4b48-afd0-2a1d0546f77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.4014\n",
      "Epoch 2: Loss = 0.3618\n",
      "Epoch 3: Loss = 0.3361\n",
      "Epoch 4: Loss = 0.3152\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_pruned.fc.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(15):  \n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model_pruned(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb068c4-5216-4b5b-a060-947308e0c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "total, zero = count_pruned_weights(model_pruned)\n",
    "print(f\"Total params: {total:,}\")\n",
    "print(f\"Zeroed (pruned) params: {zero:,} ({100 * zero/total:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fac0f2-66fc-46f5-bfb3-4f86bbdc1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pruned.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model_pruned(x).argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"Accuracy on STL10 test set: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c88054-00f0-4c1f-99fc-d951d3f5af13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
